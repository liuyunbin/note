
## 限制
* 限制同一进程的最大连接数量
* 限制同一进程可以使用的文件描述符的最大数量
* 限制同一 IP 的最大连接数量 -- limit_conn
    * 超出的连接直接报错
* 限制每个请求的最大响应速率
    * limit_rate -------- 限制速率
    * limit_rate_after -- 发送一定数据后再限速
    * proxy_limit_rate -- 限制代理的速度
* 限制同一 IP 的最大请求数量

## limit_req -- 限制同一 IP 的请求数 -- 限速是以毫秒为单位的

limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;
limit_req zone=mylimit;
* 假设 1 秒内有 4 个请求来到
* 第一秒 第 1 个正常处理, 后 3 个直接拒绝
* 接收请求的限速是每秒 1 个
* 发给后台的限速是每秒 1 个

limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;
limit_req zone=mylimit burst=2;
* 假设一秒内有 4 个请求来到,
* 第一秒 正常处理第一个请求, 接下来 2 个请求会排队, 最后一个请求会被阻塞
* 第二秒 开始处理排队的任务, 所以客户端会看到延迟
*        新来的任务也会阻塞, 所以客户端会看到延迟
* 排队的任务每少一个, 就允许一个阻塞或新来的任务进入队列
* 所以, 第一秒, 接收请求的速率是每秒 3 个,
*       第二秒, 接收请求的速率是每秒 1 个,
*       发给后台的限速始终是每秒 1 个
* 接收请求的限速是每秒 1 个, 允许暂时突破到每秒 3 个
* 发给后台的限速是每秒 1 个

limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;
limit_req zone=mylimit burst=2 nodelay;
* 假设一秒内有 4 个请求来到,
* 第一秒 正常处理第一个请求, 接下来 2 个请求会排队, 最后一个请求直接拒绝
*        排队的请求也会发给后台, 所以可以有效的降低排队任务的延迟
*        此时, 排队的数量依然是满的
* 每过一秒会释放一个排队的空位, 直到, 排队的队列为空
* 请求到来时, 如果存在空位, 则正常填充空位, 并将请求发给后台, 否则, 拒绝
* 第一秒 接收请求的速率为每秒 3 个, 发送给后台的限速也是每秒 3 个
* 第二秒 接收请求的速率为每秒 1 个, 发送给后台的限速也是每秒 1 个
* 接收请求的限速是每秒 1 个, 允许暂时突破到每秒 3 个
* 发给后台的限速是每秒 1 个, 允许暂时突破到每秒 3 个

limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;
limit_req zone=mylimit burst=2 delay=1;
* 假设一秒内有 4 个请求来到,
* 第一秒 正常处理第一个请求, 接下来 2 个请求会排队, 最后 1 个直接阻塞
*        排队的请求中, 第一个发送给后台, 第二个继续排队中, 所以可以有效的降低第一个任务的延迟
*        此时, 排队的数量依然是满的, 发送给后台的任务依然占空位
* 每过一秒会释放一个排队的空位,
    * 如果当前空位中有任务, 将空位的任务发送给后台,
    * 否则, 如果下一个空位中有任务, 将下一个空位的任务发送给后台,
    * 直到, 排队的队列为空
* 请求到来时, 如果存在空位, 则正常填充空位, 否则, 阻塞
* 第一秒 接收请求的速率为每秒 3 个, 发送给后台的限速是每秒 2 个
* 第二秒 接收请求的速率为每秒 1 个, 发送给后台的限速是每秒 1 个
* 接收请求的限速是每秒 1 个, 允许暂时突破到每秒 3 个
* 发给后台的限速是每秒 1 个, 允许暂时突破到每秒 2 个

limit_req_log_level error;  # 超过限制后的日志报错的类别
limit_req_status    code;   # 超过限制后的返回客户端的错误码

## 限流算法
* 固定窗口计数器
    * 单位时间的请求量是固定的, 超过的请求直接丢弃
    * 假如, 限速一秒 10 个请求, 而一秒钟来了 20 个请求
    * 则, 前 10 个请求正常处理, 后 10 个请求直接丢弃
    * 假如, 第一秒的前一半没有请求, 后一半来了 10 个请求
    *       第二秒的前一半来了 10 个请求, 后一半没有请求
    * 单看每一秒都没有超量
    * 但, 第一秒的后一半到第二秒的前一半的这一秒中来了 20 个请求
* 滑动窗口计数器
    * 相比较 固定窗口计数器, 单位时间不再是完整的一秒了, 而是, 任何联系的一秒内的请求都限速
    * 假如, 限速一秒 10 个请求, 而一秒钟来了 20 个请求
    * 则, 前 10个请求正常处理, 后 10 个请求直接丢弃
    * 假如, 第一秒的前一半没有请求, 后一半来了 10 个请求
    *       第二秒的前一半来了 10 个请求, 后一半没有请求
    * 第一秒没有超量,
    * 第一秒的后一半到第二秒的前一半的这一秒中来了 20 个请求
    * 所以, 第二秒的前半段的请求也会被丢弃
    * 从而保证了第一秒的后一半到第二秒的前一半的这一秒也不会超过限速
* Leaky bucket -- 漏桶 --- 主要限制量, 尽可能的缓存
* Token bucket -- 令牌桶-- 主要限制速率

